{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-e94296adaf10>, line 145)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-e94296adaf10>\"\u001b[0;36m, line \u001b[0;32m145\u001b[0m\n\u001b[0;31m    print ','.join([voca]+[str(x) for x in llda.n_z_t[:,v]])\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Labeled Latent Dirichlet Allocation\n",
    "# This code is available under the MIT License.\n",
    "# (c)2010 Nakatani Shuyo / Cybozu Labs Inc.\n",
    "# refer to Ramage+, Labeled LDA: A supervised topic model for credit attribution in multi-labeled corpora(EMNLP2009)\n",
    "\n",
    "from optparse import OptionParser\n",
    "import sys, re, numpy\n",
    "\n",
    "def load_corpus(filename):\n",
    "    corpus = []\n",
    "    labels = []\n",
    "    labelmap = dict()\n",
    "    f = open(filename, 'r')\n",
    "    for line in f:\n",
    "        mt = re.match(r'\\[(.+?)\\](.+)', line)\n",
    "        if mt:\n",
    "            label = mt.group(1).split(',')\n",
    "            for x in label: labelmap[x] = 1\n",
    "            line = mt.group(2)\n",
    "        else:\n",
    "            label = None\n",
    "        doc = re.findall(r'\\w+(?:\\'\\w+)?',line.lower())\n",
    "        if len(doc)>0:\n",
    "            corpus.append(doc)\n",
    "            labels.append(label)\n",
    "    f.close()\n",
    "    return labelmap.keys(), corpus, labels\n",
    "\n",
    "class LLDA:\n",
    "    def __init__(self, K, alpha, beta):\n",
    "        #self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def term_to_id(self, term):\n",
    "        if term not in self.vocas_id:\n",
    "            voca_id = len(self.vocas)\n",
    "            self.vocas_id[term] = voca_id\n",
    "            self.vocas.append(term)\n",
    "        else:\n",
    "            voca_id = self.vocas_id[term]\n",
    "        return voca_id\n",
    "\n",
    "    def complement_label(self, label):\n",
    "        if not label: return numpy.ones(len(self.labelmap))\n",
    "        vec = numpy.zeros(len(self.labelmap))\n",
    "        vec[0] = 1.0\n",
    "        for x in label: vec[self.labelmap[x]] = 1.0\n",
    "        return vec\n",
    "\n",
    "    def set_corpus(self, labelset, corpus, labels):\n",
    "        labelset.insert(0, \"common\")\n",
    "        self.labelmap = dict(zip(labelset, range(len(labelset))))\n",
    "        self.K = len(self.labelmap)\n",
    "\n",
    "        self.vocas = []\n",
    "        self.vocas_id = dict()\n",
    "        self.labels = numpy.array([self.complement_label(label) for label in labels])\n",
    "        self.docs = [[self.term_to_id(term) for term in doc] for doc in corpus]\n",
    "\n",
    "        M = len(corpus)\n",
    "        V = len(self.vocas)\n",
    "\n",
    "        self.z_m_n = []\n",
    "        self.n_m_z = numpy.zeros((M, self.K), dtype=int)\n",
    "        self.n_z_t = numpy.zeros((self.K, V), dtype=int)\n",
    "        self.n_z = numpy.zeros(self.K, dtype=int)\n",
    "\n",
    "        for m, doc, label in zip(range(M), self.docs, self.labels):\n",
    "            N_m = len(doc)\n",
    "            #z_n = [label[x] for x in numpy.random.randint(len(label), size=N_m)]\n",
    "            z_n = [numpy.random.multinomial(1, label / label.sum()).argmax() for x in range(N_m)]\n",
    "            self.z_m_n.append(z_n)\n",
    "            for t, z in zip(doc, z_n):\n",
    "                self.n_m_z[m, z] += 1\n",
    "                self.n_z_t[z, t] += 1\n",
    "                self.n_z[z] += 1\n",
    "\n",
    "    def inference(self):\n",
    "        V = len(self.vocas)\n",
    "        for m, doc, label in zip(range(len(self.docs)), self.docs, self.labels):\n",
    "            for n in range(len(doc)):\n",
    "                t = doc[n]\n",
    "                z = self.z_m_n[m][n]\n",
    "                self.n_m_z[m, z] -= 1\n",
    "                self.n_z_t[z, t] -= 1\n",
    "                self.n_z[z] -= 1\n",
    "\n",
    "                denom_a = self.n_m_z[m].sum() + self.K * self.alpha\n",
    "                denom_b = self.n_z_t.sum(axis=1) + V * self.beta\n",
    "                p_z = label * (self.n_z_t[:, t] + self.beta) / denom_b * (self.n_m_z[m] + self.alpha) / denom_a\n",
    "                new_z = numpy.random.multinomial(1, p_z / p_z.sum()).argmax()\n",
    "\n",
    "                self.z_m_n[m][n] = new_z\n",
    "                self.n_m_z[m, new_z] += 1\n",
    "                self.n_z_t[new_z, t] += 1\n",
    "                self.n_z[new_z] += 1\n",
    "\n",
    "    def phi(self):\n",
    "        V = len(self.vocas)\n",
    "        return (self.n_z_t + self.beta) / (self.n_z[:, numpy.newaxis] + V * self.beta)\n",
    "\n",
    "    def theta(self):\n",
    "        \"\"\"document-topic distribution\"\"\"\n",
    "        n_alpha = self.n_m_z + self.labels * self.alpha\n",
    "        return n_alpha / n_alpha.sum(axis=1)[:, numpy.newaxis]\n",
    "\n",
    "    def perplexity(self, docs=None):\n",
    "        if docs == None: docs = self.docs\n",
    "        phi = self.phi()\n",
    "        thetas = self.theta()\n",
    "\n",
    "        log_per = N = 0\n",
    "        for doc, theta in zip(docs, thetas):\n",
    "            for w in doc:\n",
    "                log_per -= numpy.log(numpy.inner(phi[:,w], theta))\n",
    "            N += len(doc)\n",
    "        return numpy.exp(log_per / N)\n",
    "\n",
    "def main():\n",
    "    parser = OptionParser()\n",
    "    parser.add_option(\"-f\", dest=\"filename\", help=\"corpus filename\")\n",
    "    parser.add_option(\"--alpha\", dest=\"alpha\", type=\"float\", help=\"parameter alpha\", default=0.001)\n",
    "    parser.add_option(\"--beta\", dest=\"beta\", type=\"float\", help=\"parameter beta\", default=0.001)\n",
    "    parser.add_option(\"-k\", dest=\"K\", type=\"int\", help=\"number of topics\", default=20)\n",
    "    parser.add_option(\"-i\", dest=\"iteration\", type=\"int\", help=\"iteration count\", default=100)\n",
    "    (options, args) = parser.parse_args()\n",
    "    if not options.filename: parser.error(\"need corpus filename(-f)\")\n",
    "\n",
    "    labelset, corpus, labels = load_corpus(options.filename)\n",
    "\n",
    "    llda = LLDA(options.K, options.alpha, options.beta)\n",
    "    llda.set_corpus(labelset, corpus, labels)\n",
    "\n",
    "    for i in range(options.iteration):\n",
    "        sys.stderr.write(\"-- %d \" % (i + 1))\n",
    "        llda.inference()\n",
    "    #print llda.z_m_n\n",
    "\n",
    "    phi = llda.phi()\n",
    "    for v, voca in enumerate(llda.vocas):\n",
    "        print ','.join([voca]+[str(x) for x in llda.n_z_t[:,v]])\n",
    "#         print ','.join([voca]+[str(x) for x in phi[:,v]])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
